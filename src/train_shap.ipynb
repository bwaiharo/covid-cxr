{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.py converted to notebook\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install dill\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install scikit-imageF\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install imblearn\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install opencv-python\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import dill\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.summary as tf_summary\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from math import ceil\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, CategoricalAccuracy, Precision, Recall, AUC\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from models.models import *\n",
    "from visualization.visualize import *\n",
    "from custom.metrics import F1Score\n",
    "from data.preprocess import remove_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 713179760581258586\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13344244889659654879\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4115038298488115064\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14640768640\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17382872087991769951\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(histogram, class_multiplier=None):\n",
    "    '''\n",
    "    Computes weights for each class to be applied in the loss function during training.\n",
    "    :param histogram: A list depicting the number of each item in different class\n",
    "    :param class_multiplier: List of values to multiply the calculated class weights by. For further control of class weighting.\n",
    "    :return: A dictionary containing weights for each class\n",
    "    '''\n",
    "    weights = [None] * len(histogram)\n",
    "    for i in range(len(histogram)):\n",
    "        weights[i] = (1.0 / len(histogram)) * sum(histogram) / histogram[i]\n",
    "    class_weight = {i: weights[i] for i in range(len(histogram))}\n",
    "    if class_multiplier is not None:\n",
    "        class_weight = [class_weight[i] * class_multiplier[i] for i in range(len(histogram))]\n",
    "    print(\"Class weights: \", class_weight)\n",
    "    #debug\n",
    "    print(\"Class weights type:\", type(class_weight))\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_minority_oversample(train_set):\n",
    "    '''\n",
    "    Oversample the minority class using the specified algorithm\n",
    "    :param train_set: Training set image file names and labels\n",
    "    :return: A new training set containing oversampled examples\n",
    "    '''\n",
    "    X_train = train_set[[x for x in train_set.columns if x != 'label']].to_numpy()\n",
    "    if X_train.shape[1] == 1:\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "    Y_train = train_set['label'].to_numpy()\n",
    "    sampler = RandomOverSampler(random_state=np.random.randint(0, high=1000))\n",
    "    X_resampled, Y_resampled = sampler.fit_resample(X_train, Y_train)\n",
    "    filenames = X_resampled[:, 1]     # Filename is in second column\n",
    "    label_strs = X_resampled[:, 2]    # Class name is in second column\n",
    "    print(\"Train set shape before oversampling: \", X_train.shape, \" Train set shape after resampling: \", X_resampled.shape)\n",
    "    train_set_resampled = pd.DataFrame({'filename': filenames, 'label': Y_resampled, 'label_str': label_strs})\n",
    "    return train_set_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(cfg, data, callbacks, verbose=1):\n",
    "    '''\n",
    "    Train a and evaluate model on given data.\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: dict of partitioned dataset\n",
    "    :param callbacks: list of callbacks for Keras model\n",
    "    :param verbose: Verbosity mode to pass to model.fit_generator()\n",
    "    :return: Trained model and associated performance metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # If set in config file, oversample the minority class\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'random_oversample':\n",
    "        data['TRAIN'] = random_minority_oversample(data['TRAIN'])\n",
    "\n",
    "    # Create ImageDataGenerators\n",
    "    train_img_gen = ImageDataGenerator(rotation_range=10, preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    val_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    test_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "\n",
    "    # Create DataFrameIterators\n",
    "    img_shape = tuple(cfg['DATA']['IMG_DIM'])\n",
    "    y_col = 'label_str'\n",
    "    class_mode = 'categorical'\n",
    "    train_generator = train_img_gen.flow_from_dataframe(dataframe=data['TRAIN'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    val_generator = val_img_gen.flow_from_dataframe(dataframe=data['VAL'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    test_generator = test_img_gen.flow_from_dataframe(dataframe=data['TEST'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False, shuffle=False)\n",
    "\n",
    "    # Save model's ordering of class indices\n",
    "    dill.dump(test_generator.class_indices, open(cfg['PATHS']['OUTPUT_CLASS_INDICES'], 'wb'))\n",
    "\n",
    "    # Apply class imbalance strategy. We have many more X-rays negative for COVID-19 than positive.\n",
    "    histogram = np.bincount(np.array(train_generator.labels).astype(int))  # Get class distribution\n",
    "    class_weight = None\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'class_weight':\n",
    "        class_multiplier = cfg['TRAIN']['CLASS_MULTIPLIER']\n",
    "        class_multiplier = [class_multiplier[cfg['DATA']['CLASSES'].index(c)] for c in test_generator.class_indices]\n",
    "        class_weight = get_class_weights(histogram, class_multiplier)\n",
    "\n",
    "    # Define metrics.\n",
    "    covid_class_idx = test_generator.class_indices['COVID-19']   # Get index of COVID-19 class\n",
    "    thresholds = 1.0 / len(cfg['DATA']['CLASSES'])      # Binary classification threshold for a class\n",
    "    metrics = [CategoricalAccuracy(name='accuracy'),\n",
    "               Precision(name='precision', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               Recall(name='recall', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               AUC(name='auc'),\n",
    "               F1Score(name='f1score', thresholds=thresholds, class_id=covid_class_idx)]\n",
    "\n",
    "    # Define the model.\n",
    "    print('Training distribution: ', ['Class ' + list(test_generator.class_indices.keys())[i] + ': ' + str(histogram[i]) + '. '\n",
    "           for i in range(len(histogram))])\n",
    "    input_shape = cfg['DATA']['IMG_DIM'] + [3]\n",
    "    num_gpus = cfg['TRAIN']['NUM_GPUS']\n",
    "    #debug\n",
    "    print(\"******* GPU:\", num_gpus)\n",
    "    if cfg['TRAIN']['MODEL_DEF'] == 'dcnn_resnet':\n",
    "        model_def = dcnn_resnet\n",
    "    elif cfg['TRAIN']['MODEL_DEF'] == 'resnet50v2':\n",
    "        model_def = resnet50v2\n",
    "    else:\n",
    "        model_def = resnet101v2\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_BINARY'], input_shape, metrics, 2, output_bias=output_bias, gpus=num_gpus)\n",
    "    else:\n",
    "        n_classes = len(cfg['DATA']['CLASSES'])\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_MULTICLASS'], input_shape, metrics, n_classes, output_bias=output_bias,\n",
    "                          gpus=num_gpus)\n",
    "    #debug\n",
    "    print(\"histogram type\", type(histogram), histogram)\n",
    "        \n",
    "    # Train the model.\n",
    "    steps_per_epoch = ceil(train_generator.n / train_generator.batch_size)\n",
    "    val_steps = ceil(val_generator.n / val_generator.batch_size)\n",
    "    # debug\n",
    "    print(\"***** class weight\", class_weight)\n",
    "    class_weight = {0:26.589285714285715, 1:0.07643737166324435}\n",
    "    history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cfg['TRAIN']['EPOCHS'],\n",
    "                                  validation_data=val_generator, validation_steps=val_steps, callbacks=callbacks,\n",
    "                                  verbose=verbose, class_weight=class_weight)\n",
    "\n",
    "    # Run the model on the test set and print the resulting performance metrics.\n",
    "    test_results = model.evaluate(test_generator, verbose=1)\n",
    "    test_metrics = {}\n",
    "    test_summary_str = [['**Metric**', '**Value**']]\n",
    "    for metric, value in zip(model.metrics_names, test_results):\n",
    "        test_metrics[metric] = value\n",
    "        print(metric, ' = ', value)\n",
    "        test_summary_str.append([metric, str(value)])\n",
    "    return model, test_metrics, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weight = {0:26.589285714285715, 1:0.07643737166324435}\n",
    "#print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_train(cfg, data, callbacks, base_log_dir):\n",
    "    '''\n",
    "    Trains a model a series of times and returns the model with the best test set metric (specified in cfg)\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: Partitioned dataset\n",
    "    :param callbacks: List of callbacks to pass to model.fit()\n",
    "    :param base_log_dir: Base directory to write logs\n",
    "    :return: The trained Keras model with best test set performance on the metric specified in cfg\n",
    "    '''\n",
    "\n",
    "    # Load order of metric preference\n",
    "    metric_preference = cfg['TRAIN']['METRIC_PREFERENCE']\n",
    "    best_metrics = dict.fromkeys(metric_preference, 0.0)\n",
    "    if 'loss' in metric_preference:\n",
    "        best_metrics['loss'] = 100000.0\n",
    "\n",
    "    # Train NUM_RUNS models and return the best one according to the preferred metrics\n",
    "    for i in range(cfg['TRAIN']['NUM_RUNS']):\n",
    "        print(\"Training run \", i+1, \" / \", cfg['TRAIN']['NUM_RUNS'])\n",
    "        cur_callbacks = callbacks.copy()\n",
    "        cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        if base_log_dir is not None:\n",
    "            log_dir = base_log_dir + cur_date\n",
    "            cur_callbacks.append(TensorBoard(log_dir=log_dir, histogram_freq=1))\n",
    "\n",
    "        # Train the model and evaluate performance on test set\n",
    "        new_model, test_metrics, test_generator = train_model(cfg, data, cur_callbacks, verbose=1)\n",
    "\n",
    "        # Log test set results and images\n",
    "        if base_log_dir is not None:\n",
    "            log_test_results(cfg, new_model, test_generator, test_metrics, log_dir)\n",
    "\n",
    "        # If this model outperforms the previous ones based on the specified metric preferences, save this one.\n",
    "        for i in range(len(metric_preference)):\n",
    "            if (((metric_preference[i] == 'loss') and (test_metrics[metric_preference[i]] < best_metrics[metric_preference[i]]))\n",
    "                    or ((metric_preference[i] != 'loss') and (test_metrics[metric_preference[i]] > best_metrics[metric_preference[i]]))):\n",
    "                best_model = new_model\n",
    "                best_metrics = test_metrics\n",
    "                best_generator = test_generator\n",
    "                best_model_date = cur_date\n",
    "                break\n",
    "            elif (test_metrics[metric_preference[i]] == best_metrics[metric_preference[i]]):\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print(\"Best model test metrics: \", best_metrics)\n",
    "    return best_model, best_metrics, best_generator, best_model_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_hparam_search(cfg, data, callbacks, log_dir):\n",
    "    '''\n",
    "    Conduct a random hyperparameter search over the ranges given for the hyperparameters in config.yml and log results\n",
    "    in TensorBoard. Model is trained x times for y random combinations of hyperparameters.\n",
    "    :param cfg: Project config\n",
    "    :param data: Dict containing the partitioned datasets\n",
    "    :param callbacks: List of callbacks for Keras model (excluding TensorBoard)\n",
    "    :param log_dir: Base directory in which to store logs\n",
    "    :return: (Last model trained, resultant test set metrics, test data generator)\n",
    "    '''\n",
    "\n",
    "    # Define HParam objects for each hyperparameter we wish to tune.\n",
    "    hp_ranges = cfg['HP_SEARCH']['RANGES']\n",
    "    HPARAMS = []\n",
    "    HPARAMS.append(hp.HParam('KERNEL_SIZE', hp.Discrete(hp_ranges['KERNEL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('MAXPOOL_SIZE', hp.Discrete(hp_ranges['MAXPOOL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('INIT_FILTERS', hp.Discrete(hp_ranges['INIT_FILTERS'])))\n",
    "    HPARAMS.append(hp.HParam('FILTER_EXP_BASE', hp.IntInterval(hp_ranges['FILTER_EXP_BASE'][0], hp_ranges['FILTER_EXP_BASE'][1])))\n",
    "    HPARAMS.append(hp.HParam('NODES_DENSE0', hp.Discrete(hp_ranges['NODES_DENSE0'])))\n",
    "    HPARAMS.append(hp.HParam('CONV_BLOCKS', hp.IntInterval(hp_ranges['CONV_BLOCKS'][0], hp_ranges['CONV_BLOCKS'][1])))\n",
    "    HPARAMS.append(hp.HParam('DROPOUT', hp.Discrete(hp_ranges['DROPOUT'])))\n",
    "    HPARAMS.append(hp.HParam('LR', hp.RealInterval(hp_ranges['LR'][0], hp_ranges['LR'][1])))\n",
    "    HPARAMS.append(hp.HParam('OPTIMIZER', hp.Discrete(hp_ranges['OPTIMIZER'])))\n",
    "    HPARAMS.append(hp.HParam('L2_LAMBDA', hp.Discrete(hp_ranges['L2_LAMBDA'])))\n",
    "    HPARAMS.append(hp.HParam('BATCH_SIZE', hp.Discrete(hp_ranges['BATCH_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('IMB_STRATEGY', hp.Discrete(hp_ranges['IMB_STRATEGY'])))\n",
    "\n",
    "    # Define test set metrics that we wish to log to TensorBoard for each training run\n",
    "    HP_METRICS = [hp.Metric(metric, display_name='Test ' + metric) for metric in cfg['HP_SEARCH']['METRICS']]\n",
    "\n",
    "    # Configure TensorBoard to log the results\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams_config(hparams=HPARAMS, metrics=HP_METRICS)\n",
    "\n",
    "    # Complete a number of training runs at different hparam values and log the results.\n",
    "    repeats_per_combo = cfg['HP_SEARCH']['REPEATS']   # Number of times to train the model per combination of hparams\n",
    "    num_combos = cfg['HP_SEARCH']['COMBINATIONS']     # Number of random combinations of hparams to attempt\n",
    "    num_sessions = num_combos * repeats_per_combo       # Total number of runs in this experiment\n",
    "    model_type = 'DCNN_BINARY' if cfg['TRAIN']['CLASS_MODE'] == 'binary' else 'DCNN_MULTICLASS'\n",
    "    trial_id = 0\n",
    "    for group_idx in range(num_combos):\n",
    "        rand = random.Random()\n",
    "        HPARAMS = {h: h.domain.sample_uniform(rand) for h in HPARAMS}\n",
    "        hparams = {h.name: HPARAMS[h] for h in HPARAMS}  # To pass to model definition\n",
    "        for repeat_idx in range(repeats_per_combo):\n",
    "            trial_id += 1\n",
    "            print(\"Running training session %d/%d\" % (trial_id, num_sessions))\n",
    "            print(\"Hparam values: \", {h.name: HPARAMS[h] for h in HPARAMS})\n",
    "            trial_logdir = os.path.join(log_dir, str(trial_id))     # Need specific logdir for each trial\n",
    "            callbacks_hp = callbacks + [TensorBoard(log_dir=trial_logdir, profile_batch=0, write_graph=False)]\n",
    "\n",
    "            # Set values of hyperparameters for this run in config file.\n",
    "            for h in hparams:\n",
    "                if h in ['LR', 'L2_LAMBDA']:\n",
    "                    val = 10 ** hparams[h]      # These hyperparameters are sampled on the log scale.\n",
    "                else:\n",
    "                    val = hparams[h]\n",
    "                cfg['NN'][model_type][h] = val\n",
    "\n",
    "            # Set some hyperparameters that are not specified in model definition.\n",
    "            cfg['TRAIN']['BATCH_SIZE'] = hparams['BATCH_SIZE']\n",
    "            cfg['TRAIN']['IMB_STRATEGY'] = hparams['IMB_STRATEGY']\n",
    "\n",
    "            # Run a training session and log the performance metrics on the test set to HParams dashboard in TensorBoard\n",
    "            with tf.summary.create_file_writer(trial_logdir).as_default():\n",
    "                hp.hparams(HPARAMS, trial_id=str(trial_id))\n",
    "                model, test_metrics, test_generator = train_model(cfg, data, callbacks_hp, verbose=0)\n",
    "                for metric in HP_METRICS:\n",
    "                    if metric._tag in test_metrics:\n",
    "                        tf.summary.scalar(metric._tag, test_metrics[metric._tag], step=1)   # Log test metric\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_test_results(cfg, model, test_generator, test_metrics, log_dir):\n",
    "    '''\n",
    "    Visualize performance of a trained model on the test set. Optionally save the model.\n",
    "    :param cfg: Project config\n",
    "    :param model: A trained Keras model\n",
    "    :param test_generator: A Keras generator for the test set\n",
    "    :param test_metrics: Dict of test set performance metrics\n",
    "    :param log_dir: Path to write TensorBoard logs\n",
    "    '''\n",
    "\n",
    "    # Visualization of test results\n",
    "    test_predictions = model.predict(test_generator, verbose=0)\n",
    "    test_labels = test_generator.labels\n",
    "    covid_idx = test_generator.class_indices['COVID-19']\n",
    "    plt = plot_roc(\"Test set\", test_labels, test_predictions, class_id=covid_idx)\n",
    "    roc_img = plot_to_tensor()\n",
    "    plt = plot_confusion_matrix(test_labels, test_predictions, class_id=covid_idx)\n",
    "    cm_img = plot_to_tensor()\n",
    "\n",
    "    # Log test set results and plots in TensorBoard\n",
    "    writer = tf_summary.create_file_writer(logdir=log_dir)\n",
    "\n",
    "    # Create table of test set metrics\n",
    "    test_summary_str = [['**Metric**','**Value**']]\n",
    "    thresholds = cfg['TRAIN']['THRESHOLDS']  # Load classification thresholds\n",
    "    for metric in test_metrics:\n",
    "        if metric in ['precision', 'recall'] and isinstance(metric, list):\n",
    "            metric_values = dict(zip(thresholds, test_metrics[metric]))\n",
    "        else:\n",
    "            metric_values = test_metrics[metric]\n",
    "        test_summary_str.append([metric, str(metric_values)])\n",
    "\n",
    "    # Create table of model and train config values\n",
    "    hparam_summary_str = [['**Variable**', '**Value**']]\n",
    "    for key in cfg['TRAIN']:\n",
    "        hparam_summary_str.append([key, str(cfg['TRAIN'][key])])\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "    else:\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "\n",
    "    # Write to TensorBoard logs\n",
    "    with writer.as_default():\n",
    "        tf_summary.text(name='Test set metrics', data=tf.convert_to_tensor(test_summary_str), step=0)\n",
    "        tf_summary.text(name='Run hyperparameters', data=tf.convert_to_tensor(hparam_summary_str), step=0)\n",
    "        tf_summary.image(name='ROC Curve (Test Set)', data=roc_img, step=0)\n",
    "        tf_summary.image(name='Confusion Matrix (Test Set)', data=cm_img, step=0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_experiment(cfg=None, experiment='single_train', save_weights=True, write_logs=True):\n",
    "    '''\n",
    "    Defines and trains HIFIS-v2 model. Prints and logs relevant metrics.\n",
    "    :param experiment: The type of training experiment. Choices are {'single_train'}\n",
    "    :param save_weights: A flag indicating whether to save the model weights\n",
    "    :param write_logs: A flag indicating whether to write TensorBoard logs\n",
    "    :return: A dictionary of metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # Load project config data\n",
    "    if cfg is None:\n",
    "        cfg = yaml.full_load(open(os.getcwd() + \"/config.yml\", 'r'))\n",
    "\n",
    "    # Set logs directory\n",
    "    cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    print(cfg['PATHS']['LOGS'])\n",
    "    log_dir = cfg['PATHS']['LOGS'] + \"training/\" + cur_date if write_logs else None\n",
    "    if not os.path.exists(cfg['PATHS']['LOGS'] + \"training\\\\\"):\n",
    "        os.makedirs(cfg['PATHS']['LOGS'] + \"training\\\\\")\n",
    "\n",
    "    # Load dataset file paths and labels\n",
    "    data = {}\n",
    "    data['TRAIN'] = pd.read_csv(cfg['PATHS']['TRAIN_SET'])\n",
    "    data['VAL'] = pd.read_csv(cfg['PATHS']['VAL_SET'])\n",
    "    data['TEST'] = pd.read_csv(cfg['PATHS']['TEST_SET'])\n",
    "\n",
    "    # Set callbacks.\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=cfg['TRAIN']['PATIENCE'], mode='min', restore_best_weights=True)\n",
    "    callbacks = [early_stopping]\n",
    "\n",
    "    # Conduct the desired train experiment\n",
    "    if experiment == 'hparam_search':\n",
    "        log_dir = cfg['PATHS']['LOGS'] + \"hparam_search\\\\\" + cur_date\n",
    "        random_hparam_search(cfg, data, callbacks, log_dir)\n",
    "    else:\n",
    "        if experiment == 'multi_train':\n",
    "            base_log_dir = cfg['PATHS']['LOGS'] + \"training\\\\\" if write_logs else None\n",
    "            model, test_metrics, test_generator, cur_date = multi_train(cfg, data, callbacks, base_log_dir)\n",
    "        else:\n",
    "            if write_logs:\n",
    "                tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                callbacks.append(tensorboard)\n",
    "            #\n",
    "            '''\n",
    "            print(cfg)\n",
    "            print(data)\n",
    "            print(callbacks)\n",
    "            '''\n",
    "            model, test_metrics, test_generator = train_model(cfg, data, callbacks)\n",
    "            if write_logs:\n",
    "                log_test_results(cfg, model, test_generator, test_metrics, log_dir)\n",
    "        if save_weights:\n",
    "            model_path = cfg['PATHS']['MODEL_WEIGHTS'] + 'model' + cur_date + '.h5'\n",
    "            save_model(model, model_path)  # Save the model's weights\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/covid-cxr/results/logs/\n",
      "Found 1489 non-validated image filenames belonging to 2 classes.\n",
      "Found 146 non-validated image filenames belonging to 2 classes.\n",
      "Found 182 non-validated image filenames belonging to 2 classes.\n",
      "Class weights:  [26.589285714285715, 0.07643737166324435]\n",
      "Class weights type: <class 'list'>\n",
      "Training distribution:  ['Class COVID-19: 28. ', 'Class non-COVID-19: 1461. ']\n",
      "******* GPU: 1\n",
      "MODEL CONFIG:  {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 3, 'NODES_DENSE0': 128, 'LR': 1e-05, 'OPTIMIZER': 'adam', 'DROPOUT': 0.4, 'L2_LAMBDA': 0.0001}\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv0_0 (Conv2D)                (None, 224, 224, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 16) 64          conv0_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 224, 224, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv0_1 (Conv2D)                (None, 224, 224, 16) 2320        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat0 (Concatenate)           (None, 224, 224, 19) 0           conv0_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 19) 76          concat0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 224, 224, 19) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 112, 112, 19) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_0 (Conv2D)                (None, 112, 112, 48) 8256        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 48) 192         conv1_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 112, 112, 48) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 112, 112, 48) 20784       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat1 (Concatenate)           (None, 112, 112, 67) 0           conv1_1[0][0]                    \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 67) 268         concat1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 112, 112, 67) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 67)   0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_0 (Conv2D)                (None, 56, 56, 144)  86976       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 144)  576         conv2_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 56, 56, 144)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                (None, 56, 56, 144)  186768      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat2 (Concatenate)           (None, 56, 56, 211)  0           conv2_1[0][0]                    \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 211)  844         concat2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 56, 56, 211)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 211)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 165424)       0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 165424)       0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          21174400    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Activation)             (None, 2)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,482,230\n",
      "Trainable params: 21,481,220\n",
      "Non-trainable params: 1,010\n",
      "__________________________________________________________________________________________________\n",
      "histogram type <class 'numpy.ndarray'> [1461   28]\n",
      "***** class weight [26.589285714285715, 0.07643737166324435]\n",
      "Epoch 1/3\n",
      " 1/47 [..............................] - ETA: 0s - loss: 420.4840 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - f1score: 0.0000e+00WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "47/47 [==============================] - 80s 2s/step - loss: 409.7465 - accuracy: 0.3042 - precision: 0.0191 - recall: 0.7143 - auc: 0.2560 - f1score: 0.0372 - val_loss: 242.7583 - val_accuracy: 0.0205 - val_precision: 0.0205 - val_recall: 1.0000 - val_auc: 0.0236 - val_f1score: 0.0403\n",
      "Epoch 2/3\n",
      "47/47 [==============================] - 74s 2s/step - loss: 379.8580 - accuracy: 0.1840 - precision: 0.0210 - recall: 0.9286 - auc: 0.1340 - f1score: 0.0410 - val_loss: 226.0265 - val_accuracy: 0.0548 - val_precision: 0.0213 - val_recall: 1.0000 - val_auc: 0.0304 - val_f1score: 0.0417\n",
      "Epoch 3/3\n",
      "47/47 [==============================] - 74s 2s/step - loss: 354.7630 - accuracy: 0.3304 - precision: 0.0245 - recall: 0.8929 - auc: 0.2833 - f1score: 0.0478 - val_loss: 232.1483 - val_accuracy: 0.0753 - val_precision: 0.0217 - val_recall: 1.0000 - val_auc: 0.0349 - val_f1score: 0.0426\n",
      "6/6 [==============================] - 5s 898ms/step - loss: 233.9849 - accuracy: 0.0604 - precision: 0.0173 - recall: 0.7500 - auc: 0.0331 - f1score: 0.0339 \n",
      "loss  =  233.98486328125\n",
      "accuracy  =  0.06043956056237221\n",
      "precision  =  0.017341040074825287\n",
      "recall  =  0.75\n",
      "auc  =  0.033118002116680145\n",
      "f1score  =  0.033898305147886276\n",
      "True (-)ves:  8 \n",
      "False (+)ves:  170 \n",
      "False (-)ves:  1 \n",
      "True (+)ves:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cfg = yaml.full_load(open(\"/home/ubuntu/covid-cxr/config.yml\", 'r'))\n",
    "    cfg['TRAIN']['EXPERIMENT_TYPE']\n",
    "    train_experiment(cfg=cfg, experiment=cfg['TRAIN']['EXPERIMENT_TYPE'], save_weights=True, write_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: ip-172-31-82-217\n",
      "IP Address: 172.31.82.217\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "## getting the hostname by socket.gethostname() method\n",
    "hostname = socket.gethostname()\n",
    "## getting the IP address using socket.gethostbyname() method\n",
    "ip_address = socket.gethostbyname(hostname)\n",
    "## printing the hostname and ip_address\n",
    "print(f\"Hostname: {hostname}\")\n",
    "print(f\"IP Address: {ip_address}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /home/ubuntu/covid-cxr/results/logs --host {ip_address}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
